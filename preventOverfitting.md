earlystopping:
-------
for each epoch 在验证集上表现下降（metirc低于阈值等），or 达到最大epoch 停止训练 <br/>

regularization:
-------
正则化的目的是惩罚模型的复杂度，避免过拟合。（加入惩罚项）<br/>
L1正则化会使得一部分模型权重变为0，从而实现特征选择的效果；<br/>
L2正则化会让模型权重尽量接近0，从而使得模型更加平滑。<br/>

dropout:
-------
Dropout是指在训练过程中，随机将一些神经元的输出设置为0，相当于把这些神经元“丢弃”。（类似relu 但不一样）<br/>
通过随机丢弃神经元，Dropout可以让神经元之间的相互依赖降低，从而让神经网络更加健壮。<br/>
